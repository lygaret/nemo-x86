#include <ext/multiboot.h>
#include <stdlib/stdlib.h>
#include <kernel/h/isr.h>
#include <kernel/h/panic.h>
#include <kernel/h/pmm.h>
#include <kernel/h/screen.h>
#include <kernel/h/stdio.h>

uintptr_t * pagedir    = (uintptr_t *) 0xFFFFF000;
uintptr_t * pagetables = (uintptr_t *) 0xFFC00000;

extern uintptr_t * _kernend;

uintptr_t pmm_free_stack = 0;
unsigned  pmm_free_total = 0;

// kernel alloc-only starts right after identity page mapping
uintptr_t vmm_base = 0x00400000;

void pmm_map_page(uintptr_t paddr, uintptr_t vaddr, unsigned flags) {
  uintptr_t pdindex = vaddr >> 22;
  uintptr_t ptindex = vaddr >> 12 & 0x03FF;

  page_directory_t dir = bootpagedir[pdindex];
  if (!dir.present) {
    // allocate a page from the free list
  }
}

static inline void flush_tlb(uintptr_t addr) {
   asm volatile("invlpg (%0)" ::"r" (addr) : "memory");
}

void vmm_fault_handler(isr_registers_t *regs) {
  bool present      = regs->errcode & 1;
  bool write        = regs->errcode & 2;
  bool user         = regs->errcode & 4;
  bool reserved     = regs->errcode & 8;
  bool instruction  = regs->errcode & 16;

  uintptr_t address;
  asm volatile ("movl %%cr2, %0" : "=r" (address));

  kprintf("present: %B\n", present);
  kprintf("write: %B\n", write);
  kprintf("user: %B\n", user);
  kprintf("reserved: %B\n", reserved);
  kprintf("instruction: %B\n", instruction);
  kprintf("address: 0x%h\n", address);

  // the kernel gets whatever it wants
  if (!user && !present) {
  }

  kpanic("\n\nx.x");
}

void * kmalloc(uint32_t size, bool align, uintptr_t *phys) {
  if (align && (vmm_base & 0xFFFFF000)) {
    vmm_base &= 0xFFFFF000;
    vmm_base += 0x1000;
  }

  if (phys != NULL) {
    *phys = vmm_base;
  }

  uintptr_t tmp = vmm_base;
  vmm_base += size;
  return (void *)tmp;
}

void pmm_initialize(uintptr_t mmap_addr, size_t mmap_length) {
  kprintf("pmm_init ... ");

  // walk the free areas of the memory map, and manage these pages on the stack
  // space below 16mb is kernel reserved
  // space above is first come first served
  // kernel can steal space from shared heap if needed 

  uintptr_t virtaddr  = 0x60000000;
  unsigned  pdindex   = virtaddr >> 22;

  uintptr_t entry_addr = mmap_addr;
  while (entry_addr < (mmap_addr + mmap_length)) {
    multiboot_memory_map_t * entry = (multiboot_memory_map_t *)entry_addr;

    // skip processing if it's not marked available
    if (entry->type != MULTIBOOT_MEMORY_AVAILABLE)
      goto next;

    uintptr_t addr = (uintptr_t)entry->addr;
    uintptr_t end  = addr + entry->len;

    // skip to 4Mb aligned start
    if ((addr & ~0x3FFFFF) != addr) {
      addr = (addr + 1) & ~0x3FFFFF;
    }

    // loop over every 4k page, and mark it
    for (; addr < end; addr += 0x4000) {
      unsigned offset = addr % 0x400000;

      // if the current address is a 4Mb page boundary, temporarily map the page
      if (offset == 0) {
        pagedir[pdindex] = addr | 0b10000011;
        flush_tlb(virtaddr);
      }

      // skip over the bios, kernel
      if (addr < (uintptr_t)&_kernend) {
        continue;
      }

      // write the current stack header to the page
      if (pmm_free_stack != 0) {
        *(uint32_t *)(virtaddr + offset) = pmm_free_stack;
      }

      // update the stack pointer
      pmm_free_stack  = addr;
      pmm_free_total += 1;
    }

  next:
    entry_addr = entry_addr + entry->size + sizeof(uintptr_t);
  }

  // done! clear out the temp pagedir
  pagedir[pdindex] = 0;
  flush_tlb(virtaddr);

  // install the page fault handler
  isr_set_handler(14, &vmm_fault_handler);

  kprintf(" ok! (%d total pages, %d total Mb)\n", pmm_free_total, (pmm_free_total * 0x4000) / 0x100000);
}
